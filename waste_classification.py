# -*- coding: utf-8 -*-
"""Waste Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_AfEYQQEZjX7HoosUJ6JgHLKeaTmhWpo
"""

# streamlit_app.py
# Streamlit app: Waste classification (O vs R) with model selection & graceful fallbacks.

import streamlit as st
import os
from PIL import Image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Try imports that might be heavy — if they fail we show friendly messages
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import models, transforms as T
    TORCH_AVAILABLE = True
except Exception as e:
    TORCH_AVAILABLE = False
    TORCH_IMPORT_ERROR = str(e)

# App config
st.set_page_config(page_title="AI Waste Classifier", layout="wide")
st.title("♻️ AI-Powered Waste Classification")
st.markdown("Classify waste images into **Organic (O)** or **Recycling (R)** using deep learning models.")
st.markdown("Compare ResNet50, MobileNetV2, and EfficientNetB0 predictions with confidence scores.")

# Device
if TORCH_AVAILABLE:
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
else:
    DEVICE = "cpu"

st.sidebar.header("Settings")
st.sidebar.write(f"Device: **{DEVICE}**")

# Paths & defaults
ROOT = os.getcwd()
MODEL_DIR = os.path.join(ROOT, "models")   # put your .pth files here (optional)
os.makedirs(MODEL_DIR, exist_ok=True)

MODEL_PATHS = {
    "ResNet50": os.path.join(MODEL_DIR, "Resnet50_best.pth"),
    "MobileNetV2": os.path.join(MODEL_DIR, "MobileNetV2_best.pth"),
    "EfficientNetB0": os.path.join(MODEL_DIR, "EfficientNetB0_best.pth"),
}

CLASS_NAMES = ["Organic (O)", "Recycling (R)"]

# Transform
test_tf = T.Compose([
    T.Resize((224,224)),
    T.ToTensor(),
    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
]) if TORCH_AVAILABLE else None

# Model loader (cached)
if TORCH_AVAILABLE:
    @st.cache_resource
    def load_model(name: str):
        # Build model architecture, use ImageNet pretrained backbone if no custom checkpoint
        try:
            if name == "ResNet50":
                model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)
                model.fc = nn.Linear(model.fc.in_features, 2)
            elif name == "MobileNetV2":
                model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
                model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)
            elif name == "EfficientNetB0":
                model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)
                model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)
            else:
                raise ValueError("Unknown model name")
        except Exception as e:
            st.error(f"Model creation failed: {e}")
            raise

        # Try to load custom weights if available
        p = MODEL_PATHS.get(name)
        if p and os.path.exists(p):
            try:
                state = torch.load(p, map_location="cpu")
                model.load_state_dict(state)
                st.sidebar.success(f"Loaded custom weights for {name}")
            except Exception as e:
                st.sidebar.warning(f"Found weights at {p} but failed to load: {e}. Using ImageNet backbone.")
        else:
            st.sidebar.info(f"No custom checkpoint found for {name}; using ImageNet weights (head adapted).")

        model.to(DEVICE)
        model.eval()
        return model
else:
    def load_model(name: str):
        raise RuntimeError("PyTorch is not available in this environment. Add torch to requirements.txt and redeploy.")

# Prediction util
def predict_with_model(model, pil_img):
    """Return (pred_label_str, confidence_float, raw_probs_np)"""
    model = model.to(DEVICE)
    model.eval()
    x = test_tf(pil_img).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        logits = model(x)
        probs = F.softmax(logits, dim=1).cpu().numpy()[0]
    pred_idx = int(np.argmax(probs))
    return CLASS_NAMES[pred_idx], float(probs[pred_idx]), probs

# UI: file uploader & model selection
uploaded = st.file_uploader("Upload a waste image (jpg/png)", type=["jpg","jpeg","png"])
model_choice = st.selectbox("Choose model", list(MODEL_PATHS.keys()))

# Option to upload a custom .pth in the session (temporary)
st.sidebar.markdown("**Upload a .pth checkpoint (optional)**")
pth_file = st.sidebar.file_uploader("Upload model .pth", type=["pth"])
if pth_file:
    target_name = st.sidebar.selectbox("Which model to replace?", list(MODEL_PATHS.keys()))
    if st.sidebar.button("Save checkpoint"):
        save_path = MODEL_PATHS[target_name]
        with open(save_path, "wb") as f:
            f.write(pth_file.read())
        st.sidebar.success(f"Saved to {save_path}. Redeploy or refresh to load it.")

# If torch missing show help
if not TORCH_AVAILABLE:
    st.error("PyTorch not installed in this environment. Add `torch` and `torchvision` to requirements.txt and redeploy.")
    st.stop()

# Main action
if uploaded:
    try:
        img = Image.open(uploaded).convert("RGB")
    except Exception as e:
        st.error(f"Unable to read image: {e}")
        st.stop()

    st.image(img, caption="Uploaded image", use_column_width=True)

    # Load chosen model
    try:
        model = load_model(model_choice)
    except Exception as e:
        st.error(f"Failed to load model: {e}")
        st.stop()

    # Predict
    try:
        label, conf, probs = predict_with_model(model, img)
    except Exception as e:
        st.error(f"Inference failed: {e}")
        st.stop()

    # Show results
    st.subheader("Prediction")
    st.write(f"**{label}**  — confidence **{conf:.3f}**")

    # Confidence bar (two-bar)
    df = pd.DataFrame({"probability": probs}, index=CLASS_NAMES)
    st.bar_chart(df)

    # Compare all models quickly (if user wants)
    if st.checkbox("Compare predictions across all models"):
        table = []
        for name in MODEL_PATHS.keys():
            try:
                m = load_model(name)
                lab, cf, _ = predict_with_model(m, img)
                table.append({"Model": name, "Label": lab, "Confidence": float(cf)})
            except Exception as e:
                table.append({"Model": name, "Label": "ERROR", "Confidence": None})
        st.table(pd.DataFrame(table))

    # Try show GradCAM if available
    if st.checkbox("Show Grad-CAM explanation (requires pytorch-grad-cam)"):
        try:
            from pytorch_grad_cam import GradCAM
            from pytorch_grad_cam.utils.image import show_cam_on_image
            # get last conv layer heuristically
            if hasattr(model, "layer4"):  # ResNet
                target_layer = model.layer4[-1]
            elif hasattr(model, "features") and len(model.features) > 0:  # MobileNet/EfficientNet-ish
                target_layer = model.features[-1]
            else:
                st.warning("Could not identify target layer for Grad-CAM for this model.")
                target_layer = None

            if target_layer is not None:
                cam = GradCAM(model=model, target_layers=[target_layer])
                inp = test_tf(img).unsqueeze(0).to(DEVICE)
                grayscale_cam = cam(input_tensor=inp)[0]
                cam_img = show_cam_on_image(np.array(img.resize((224,224)))/255.0, grayscale_cam, use_rgb=True)
                st.image(cam_img, caption="Grad-CAM", use_column_width=True)
        except Exception as e:
            st.error("Grad-CAM not available (install pytorch-grad-cam in requirements.txt) or failed: " + str(e))

# Footer
st.markdown("---")
st.markdown("Repo / models: put custom `.pth` files in the `models/` folder. App gracefully uses ImageNet-pretrained backbones if no checkpoints found.")