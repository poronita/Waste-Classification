# -*- coding: utf-8 -*-
"""Waste Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_AfEYQQEZjX7HoosUJ6JgHLKeaTmhWpo
"""

!pip install streamlit

# streamlit_app.py
# Streamlit app to load a submission_package (zip) containing models, plots, csvs
# - classify uploaded images with any found models (ResNet50, MobileNetV2, EfficientNetB0)
# - show comparison, show precomputed plots & tables, show Grad-CAM if available
# - CPU-safe, defensive (won't crash if pieces are missing)

import streamlit as st
import zipfile, tempfile, os, shutil, glob
from pathlib import Path
from PIL import Image
import io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Try heavy imports gracefully
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import models, transforms as T
    TORCH = True
except Exception as e:
    TORCH = False
    TORCH_ERR = str(e)

# Try optional xai package
try:
    from pytorch_grad_cam import GradCAM
    from pytorch_grad_cam.utils.image import show_cam_on_image
    GRADCAM_AVAILABLE = True
except Exception:
    GRADCAM_AVAILABLE = False

# ----------------------------
# UI header (two-line description)
# ----------------------------
st.set_page_config(page_title="♻️ Waste Classifier (O vs R + Subclasses)", layout="wide")
st.title("♻️ AI Waste Classification")
st.markdown("Classify waste images into **Organic (O)** or **Recycling (R)** using trained models. 🚀")
st.markdown("Compare ResNet50, MobileNetV2, and EfficientNetB0 predictions, view metrics, plots, and XAI.")

# ----------------------------
# Helpers: transforms, model builders
# ----------------------------
DEVICE = "cuda" if (TORCH and torch.cuda.is_available()) else "cpu"

if TORCH:
    test_tf = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
else:
    test_tf = None

CLASS_NAMES = ["Organic (O)", "Recycling (R)"]

def build_model_by_name(name: str):
    """Return a PyTorch model architecture with final head adapted to 2 classes.
       We don't load weights here — caller will load state_dict if path available.
    """
    if not TORCH:
        raise RuntimeError("Torch is not available in the environment.")
    name = name.lower()
    if "resnet" in name:
        m = models.resnet50(weights=None)
        m.fc = nn.Linear(m.fc.in_features, 2)
    elif "mobilenet" in name:
        m = models.mobilenet_v2(weights=None)
        m.classifier[1] = nn.Linear(m.classifier[1].in_features, 2)
    elif "efficientnet" in name:
        # torchvision has efficientnet_b0
        try:
            m = models.efficientnet_b0(weights=None)
            m.classifier[1] = nn.Linear(m.classifier[1].in_features, 2)
        except Exception:
            # fallback: timm not used here to avoid extra dependency
            raise RuntimeError("EfficientNet b0 not available in torchvision in this environment.")
    else:
        raise ValueError("Unknown model architecture requested.")
    return m

@st.cache_resource
def load_model_from_path(model_path: str):
    """Load a model by inspecting filename and mapping to architecture.
       Returns (model, name) or raises error.
    """
    if not TORCH:
        raise RuntimeError("Torch not available.")
    mp = Path(model_path)
    nm = mp.name.lower()
    # Heuristic to choose architecture
    if "resnet" in nm:
        name = "ResNet50"
    elif "mobilenet" in nm or "mobilenetv2" in nm:
        name = "MobileNetV2"
    elif "efficientnet" in nm or "efficientnet_b0" in nm or "efficientnetb0" in nm:
        name = "EfficientNetB0"
    else:
        # fallback: try ResNet
        name = "ResNet50"
    model = build_model_by_name(name)
    # load weights
    try:
        state = torch.load(str(mp), map_location="cpu")
        # Some saved state may contain extra keys - handle gracefully
        try:
            model.load_state_dict(state)
        except Exception:
            # maybe saved as {'model_state_dict': ...}
            if isinstance(state, dict):
                # try common keys
                for k in ("model_state_dict", "state_dict", "net"):
                    if k in state and isinstance(state[k], dict):
                        model.load_state_dict(state[k])
                        break
                else:
                    # attempt to load by filtering keys (when saved with DataParallel)
                    filtered = {}
                    for key, val in state.items():
                        new_key = key.replace("module.", "") if key.startswith("module.") else key
                        filtered[new_key] = val
                    model.load_state_dict(filtered)
            else:
                raise
    except Exception as e:
        raise RuntimeError(f"Failed to load weights from {model_path}: {e}")
    model.to(DEVICE)
    model.eval()
    return model, name

def predict_pil(model, pil_img):
    if not TORCH:
        raise RuntimeError("Torch not available.")
    x = test_tf(pil_img).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        logits = model(x)
        probs = F.softmax(logits, dim=1).cpu().numpy()[0]
    pred_idx = int(np.argmax(probs))
    return CLASS_NAMES[pred_idx], float(probs[pred_idx]), probs

# ----------------------------
# UI: upload submission package zip (or allow using local files by drag-drop)
# ----------------------------
st.sidebar.header("1) Upload your submission package")
st.sidebar.write("Upload your `submission_package.zip` (or a zip of the folder containing models & results).")
zip_file = st.sidebar.file_uploader("submission_package.zip", type=["zip"])

# Also allow uploading a model file directly (single .pth) for quick test
st.sidebar.markdown("---")
st.sidebar.write("Or upload a single model (.pth) to test quickly.")
single_pth = st.sidebar.file_uploader("Single model (.pth)", type=["pth"])

# Temporary working dir for the session
WORKDIR = None
extracted_dir = None
models_found = {}  # mapping name->path
plots_found = []
tables_found = {}
precomputed_images = []

if zip_file:
    # save to temp file and extract
    tmp = tempfile.mkdtemp()
    WORKDIR = tmp
    zpath = os.path.join(tmp, "submission_package.zip")
    with open(zpath, "wb") as f:
        f.write(zip_file.getbuffer())
    try:
        with zipfile.ZipFile(zpath, "r") as zf:
            zf.extractall(tmp)
        st.sidebar.success("Archive extracted.")
    except Exception as e:
        st.sidebar.error(f"Failed to extract zip: {e}")
        WORKDIR = None

# If single model uploaded, save in temp dir too
if single_pth:
    tmp2 = tempfile.mkdtemp()
    WORKDIR = tmp2 if WORKDIR is None else WORKDIR
    spath = os.path.join(WORKDIR, single_pth.name)
    with open(spath, "wb") as f:
        f.write(single_pth.getbuffer())

# If WORKDIR is set, scan for assets
if WORKDIR:
    extracted_dir = WORKDIR
    # search for model files
    for root, dirs, files in os.walk(extracted_dir):
        for fn in files:
            ln = fn.lower()
            if ln.endswith(".pth") or ln.endswith(".pt"):
                p = os.path.join(root, fn)
                # pick a friendly label
                if "resnet" in ln:
                    models_found["ResNet50"] = p
                elif "mobilenet" in ln or "mobile" in ln:
                    models_found["MobileNetV2"] = p
                elif "efficient" in ln:
                    models_found["EfficientNetB0"] = p
                else:
                    # place under generic
                    models_found.setdefault("Other", []).append(p)
            # capture plots
            if ln.endswith(".png") or ln.endswith(".jpg") or ln.endswith(".jpeg"):
                p = os.path.join(root, fn)
                precomputed_images.append(p)
            # capture CSV/tables
            if ln.endswith(".csv") or ln.endswith(".tex") or ln.endswith(".json") or ln.endswith(".txt"):
                p = os.path.join(root, fn)
                tables_found[fn] = p

# ----------------------------
# Main layout: left column for controls, right for outputs
# ----------------------------
col1, col2 = st.columns([1, 2])

with col1:
    st.header("Step A — Load & Inspect package")
    if not WORKDIR:
        st.info("Upload your `submission_package.zip` (or a single model .pth) from your local machine (e.g. C:\\Users\\thepr\\Downloads\\submission_package.zip).")
    else:
        st.success(f"Loaded package from temporary folder.")
        st.write("Found models:")
        if models_found:
            for k, v in models_found.items():
                if isinstance(v, list):
                    for p in v:
                        st.write(f"- {k}: {os.path.basename(p)}")
                else:
                    st.write(f"- {k}: {os.path.basename(v)}")
        else:
            st.write("No model `.pth` files detected in package.")

        st.write("Found tables / csvs:")
        if tables_found:
            for fn, p in tables_found.items():
                st.write(f"- {fn}")
        else:
            st.write("No CSV / tables detected.")

        st.write("Found precomputed plots:")
        if precomputed_images:
            st.write(f"- {len(precomputed_images)} images (ROC, Grad-CAM etc.)")
        else:
            st.write("- None found")

    st.markdown("---")
    st.header("Step B — Test image")
    uploaded_img = st.file_uploader("Upload test image to classify (jpg/png)", type=["jpg", "jpeg", "png"])

    st.markdown("Model selection (if multiple found)")
    model_options = ["Use ImageNet backbone (no weights)"]
    # extend model options if found
    for mn in ["ResNet50", "MobileNetV2", "EfficientNetB0"]:
        if mn in models_found:
            model_options.append(mn)
    st_model_choice = st.selectbox("Model to use:", model_options)

    # Option: show precomputed metrics
    show_metrics = st.checkbox("Show package metrics & tables", value=True)

with col2:
    st.header("Results & Visuals")

    # Show tables/metrics if available
    if show_metrics and tables_found:
        st.subheader("Precomputed Metrics & Tables (from package)")
        # show up to a few important CSVs if present
        # prefer metrics_summary, results_table_updated, final_results, per_class_report
        prefer = ["metrics_summary.csv", "results_table_updated.csv", "results_table.csv",
                  "final_results.csv", "per_class_report.txt", "per_class_report.csv",
                  "step11_results.csv", "step15_results.csv", "metrics.csv"]
        shown = set()
        for p in prefer:
            if p in tables_found:
                try:
                    if p.endswith(".txt"):
                        with open(tables_found[p], "r", encoding="utf-8", errors="ignore") as f:
                            text = f.read(20000)
                        st.markdown(f"**{p}**")
                        st.text(text)
                    else:
                        df = pd.read_csv(tables_found[p])
                        st.markdown(f"**{p}**")
                        st.dataframe(df)
                    shown.add(p)
                except Exception as e:
                    st.write(f"Could not show {p}: {e}")

        # show any other CSVs
        other_csvs = [k for k in tables_found.keys() if k.endswith(".csv") and k not in shown]
        for k in other_csvs:
            try:
                df = pd.read_csv(tables_found[k])
                st.markdown(f"**{k}**")
                st.dataframe(df.head(50))
            except Exception as e:
                st.write(f"Could not read {k}: {e}")

    # Show precomputed images (ROC, PR, gradcam averages)
    if precomputed_images:
        st.subheader("Precomputed Plots & XAI Images")
        # show images grouped by filename keywords
        keywords = [("roc", "ROC curve"), ("pr", "Precision-Recall"), ("gradcam", "Grad-CAM"),
                    ("reliability", "Reliability"), ("confusion", "Confusion Matrix"), ("step15", "Step15")]
        shown_imgs = set()
        for kw, label in keywords:
            matches = [p for p in precomputed_images if kw in p.lower()]
            if matches:
                st.markdown(f"**{label}**")
                cols = st.columns(min(3, len(matches)))
                for i, m in enumerate(matches):
                    try:
                        img = Image.open(m).convert("RGB")
                        cols[i % len(cols)].image(img, caption=os.path.basename(m))
                        shown_imgs.add(m)
                    except Exception:
                        pass
        # show leftover images
        leftovers = [p for p in precomputed_images if p not in shown_imgs]
        if leftovers:
            st.markdown("**Other images**")
            for p in leftovers[:12]:
                try:
                    st.image(Image.open(p).convert("RGB"), caption=os.path.basename(p))
                except Exception:
                    pass

    # If user uploaded a test image and a model selected, run prediction
    if uploaded_img and st_model_choice:
        try:
            pil = Image.open(uploaded_img).convert("RGB")
        except Exception as e:
            st.error(f"Could not open uploaded image: {e}")
            pil = None

        if pil is not None:
            # if using a found model
            if st_model_choice != "Use ImageNet backbone (no weights)":
                mp = models_found.get(st_model_choice)
                if mp:
                    # load model
                    try:
                        model, arch = load_model_from_path(mp)
                    except Exception as e:
                        st.error(f"Failed to load model from {mp}: {e}")
                        model = None
                else:
                    st.error("Selected model path not found.")
                    model = None
            else:
                # build imageNet-backbone model (no custom weights) for demo
                try:
                    model = build_model_by_name("ResNet50")
                    # we keep random init / untrained head, but that's okay for demo
                    model.to(DEVICE).eval()
                except Exception as e:
                    st.error(f"Could not construct fallback model: {e}")
                    model = None

            if model is not None:
                # run prediction
                try:
                    label, conf, probs = predict_pil(model, pil)
                    st.subheader("Live Prediction")
                    st.write(f"**Predicted:** {label}   |   **Confidence:** {conf:.3f}")
                    # show bar chart
                    dfp = pd.DataFrame({"confidence": probs}, index=CLASS_NAMES)
                    st.bar_chart(dfp)
                except Exception as e:
                    st.error(f"Inference error: {e}")
                    label, conf, probs = None, None, None

                # Show Grad-CAM if available or if precomputed gradcam present
                if st.checkbox("Show Grad-CAM explanation (live)"):
                    if GRADCAM_AVAILABLE and model is not None:
                        try:
                            # heuristics for picking target layer
                            if hasattr(model, "layer4"):
                                target = model.layer4[-1]
                            elif hasattr(model, "features") and len(model.features) > 0:
                                target = model.features[-1]
                            else:
                                target = None
                            if target is None:
                                st.warning("Could not determine target layer for this model.")
                            else:
                                cam = GradCAM(model=model, target_layers=[target])
                                inp = test_tf(pil).unsqueeze(0).to(DEVICE)
                                grayscale_cam = cam(input_tensor=inp)[0]
                                cam_img = show_cam_on_image(np.array(pil.resize((224,224)))/255.0, grayscale_cam, use_rgb=True)
                                st.image(cam_img, caption="Grad-CAM (live)", use_column_width=True)
                        except Exception as e:
                            st.error(f"Live Grad-CAM failed: {e}")
                    else:
                        st.info("Live Grad-CAM not available in this environment. Showing precomputed Grad-CAMs if present.")
                        # show precomputed if present
                        grads = [p for p in precomputed_images if "gradcam" in p.lower() or "grad_cam" in p.lower()]
                        if grads:
                            for g in grads[:6]:
                                try:
                                    st.image(Image.open(g).convert("RGB"), caption=os.path.basename(g))
                                except Exception:
                                    pass
                        else:
                            st.write("No precomputed Grad-CAM images found in package.")

            # Show model performance summary + text explanation if available
            st.markdown("---")
            st.subheader("Model Details & Explanation")
            # show model files & sizes
            if models_found:
                for k, p in models_found.items():
                    if isinstance(p, list):
                        for q in p:
                            st.write(f"{k}: {os.path.basename(q)} ({round(os.path.getsize(q)/1e6,2)} MB)")
                    else:
                        st.write(f"{k}: {os.path.basename(p)} ({round(os.path.getsize(p)/1e6,2)} MB)")

            # show results summary if any table exists
            prefer_summary = None
            for key in ("results_table_updated.csv", "results_table.csv", "metrics_summary.csv", "final_results.csv", "results_table.csv"):
                if key in tables_found:
                    prefer_summary = tables_found[key]; break
            if prefer_summary:
                try:
                    df = pd.read_csv(prefer_summary)
                    st.markdown("**Summary table from package**")
                    st.dataframe(df)
                except Exception as e:
                    st.write("Could not load summary CSV:", e)

            # show textual summaries
            for textfile in ("results_summary_auto.txt", "results_summary_cb.txt", "thesis_summary.txt", "results_summary.txt", "results_report.txt"):
                if textfile in tables_found:
                    try:
                        with open(tables_found[textfile], "r", encoding="utf-8", errors="ignore") as f:
                            txt = f.read(6000)
                        st.markdown(f"**{textfile}**")
                        st.text(txt)
                    except Exception:
                        pass

    else:
        st.info("Upload a test image and pick a model to see live classification.")

# Footer: cleanup option
st.sidebar.markdown("---")
if WORKDIR and st.sidebar.button("Clear uploaded package & cleanup"):
    try:
        shutil.rmtree(WORKDIR)
        st.sidebar.success("Temporary package folder removed. Refresh page.")
    except Exception as e:
        st.sidebar.error(f"Failed to cleanup: {e}")

# End
st.markdown("---")
st.markdown("Made for thesis/demo use — upload your `submission_package.zip` to load models, metrics, and precomputed XAI images.")





